Итоговый файл - ml_alcohol4no_conc.py (прикрепил, есть и на github https://github.com/qrspeter/ml_alcohol.git)

1. Построить более сложную модель с подбором гиперпараметров

Построил модель с использованием Grid Search и Randomized Search:

    grid classification_report (1000 and 3000 iterations):
                   precision    recall  f1-score   support
    
       1-Octanol       1.00      1.00      1.00        13
      1-Propanol       0.45      0.62      0.53         8
    1-isobutanol       0.50      0.21      0.30        14
       2-Butanol       0.72      0.93      0.81        14
      2-propanol       0.80      0.86      0.83        14
    
        accuracy                           0.73        63
       macro avg       0.70      0.72      0.69        63
    weighted avg       0.71      0.73      0.70        63

    random classification_report:
               precision    recall  f1-score   support

   1-Octanol       1.00      1.00      1.00        13
  1-Propanol       0.29      0.62      0.40         8
1-isobutanol       0.00      0.00      0.00        14
   2-Butanol       0.60      0.86      0.71        14
  2-propanol       0.92      0.79      0.85        14

    accuracy                           0.65        63
   macro avg       0.56      0.65      0.59        63
weighted avg       0.58      0.65      0.60        63

Также применил Halving Grid Search, но не понял что с этим можно делать дальше. Картинку прикрепил.


Ошибочно решил что случайная классификация интереснее и дальше опирался на неё. Но суть работы не меняется - просто надо закоментировать блок Grid и раскомментировать блок Random.

Далее - убрал из базы данных упоминание о концентрации. С одной стороны - надо было также разделить данные по концентрациям и определить при каких концентрациях алгорит еще надежно работает, а на каких - нет. С другой - это бы сделало базу для каждого обучения совсем небольшой (250/5=50). Кроме того, в опытах используются очень большие концентрации, и они все должны распознаваться. Поэтому и принято такое решение.

Следующим шагом изменен алгоритм работы с базой - если ранее все варианты датчиков анализировались в одной куче, теперь анализ проходит для данных с каждого сенсора отдельно в цикле, и результаты (classification_report в формате словаря, из которого убираются элементы статистики, чтобы не мешать перебирать по спиртам) собираются в список (цикл "for i, sensor in enumerate(data_lst)"):

    precision_tpl = (sens_name, report_dict)
    precision.append(precision_tpl)

После окончания перебора сенсоров данные о точности распознавания спиртов разными менсорами выводятся в виде графика (прикреплен).



Дополнительно для каждого сенсора "вручную" проверил происходит как для разных сенсоров будут конвертироватся экспериментальные значения. Так, задавая ряд нормированных значений (0.02, 0.22...0.82), стало видно, что показания различаются для среденй части диапазона (0.42), а на крайние значения все сенсоры дают одинаковый результат (это то же самое, что показывает таблица, но проверял чтобы понять как можно получать предсказание, а не смотреть на цифры точности модели):

    # test_predict for
    # 0.02 = ['2-Butanol']     
    # 0.22 = ['2-Butanol']
    # 0.42 = ['1-Propanol']
    # 0.42 = ['2-Butanol']
    # 0.42 = ['1-Propanol']
    # 0.42 = ['2-Butanol']
    # 0.42 = ['1-Propanol']
    # 0.62 = ['1-Propanol']
    # 0.82 = ['1-Octanol']

 То, как вводить реальные значения, а не нормированные, понял не сразу, потому тестировал на нормированных данных. Так то перевод экспериментальных данных в нормированные проверил тоже (экспериментальному значению -50 соответствует нормированное 0.85):

    test = np.array([-50])
    scaled_test = min_max_scaler.transform(test.reshape(-1,1))
    print('for test_value = %5.2f ' % test, 'test_predict = ', scaled_test)
    # for test_value = -50.00 test_predict =  [[0.85436221]]  


2. Проинтерпретировать полученную модель

Прикрепленный график наглядно показывает эффективность использования выбранных сенсоров для распознавания типа спирта - она довольно низкая, превышает 50% только для октанола и изобутанола (с подсказкой о концентрации точность выше - также график прикрепил, но причины отказа от такой модели привел выше).

Точность для бутанола указывается как 0, но вероятнее всего это из-за каких-то проблем при расчетах (не смог понять из-за чего именно в коде возникает предупреждение "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior." и ограничился выставление значения zero_division=0).

Учитывая что все пять сенсоров (отличающихся соотношением двух рабочающих каналов) показали схожий тренд по чувствительности относительно спиртов, изначально был неверно выбран тип сенсора. Лучше всего было брать два сенсора, которые по-разному реагируют на спирты, например второй - куда более специфично на бутанол (на который выбранные сенсоры дают нулевую точность), и хуже всего на октанол.  В рамках одного сенсора выбранного типа результаты я бы признал неудачными.

Авторы статьи, из которой и брался набор данных, боеле оптимистичны, и пишут "All the five of the QCM sensors gave successful results, but QCM12-constructed using only NP-was the most successful... The results of 300 different scenarios showed that different alcohols can be classified successfully by using ANN-ABC on the sensor data from QCM12." (https://www.sciencedirect.com/science/article/pii/S2215098619303337).

С чем можно согласиться - с тем, что сенсор QCM12 показал наилучшие результаты и у нас тоже.  Возможно разница объясняется и тем, что в статье использовались более продвинутые алгоритмы (Artificial Neural Network (ANN) with Artificial Bee Colony algorithm)